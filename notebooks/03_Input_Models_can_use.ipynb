{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cade2cfa",
   "metadata": {},
   "source": [
    "# Creating Input a Neural Net Model can actually use.\n",
    "\n",
    "Up until this point in the notebooks we turned the file into a `Pandas DataFrame ` object. This is very conventient to get to know the data and run some basic analytics on it, but it's not something a Neural Net Model can directly use. We'll have to turn the `DataFrames` into `Numpy` arrays. Those can almost directly be used by a Neural Net, for instance by wrapping them into a Pytorch `DataLoader` object.\n",
    "\n",
    "There are some differences between a DataFrame and a Numpy Array. An important one is that a DataFrame can have different data-type for each column (feature). We made `DataFrames` with 'object' (string), 'float', 'categorical' datatypes, all in one DataFrame.\n",
    "\n",
    "That is not possible with `Numpy` Arrays, a specific Numpy array has to have a single DataType. It needs a homogeneous datatype across the entire array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670789a5",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "Before running the experiment, make sure to import the `numpy`, `pandas` and `numba` packages in your virtual environment\n",
    "```\n",
    "> pip install numpy\n",
    "> pip install pandas\n",
    "> pip install numba\n",
    "```\n",
    "And that the notebook can find the `f3atur3s` and `eng1n3` packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e2a02",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Before creating features, we will have to import a couple of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be56e4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import f3atur3s as ft\n",
    "import eng1n3.pandas as en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961a2ca",
   "metadata": {},
   "source": [
    "And we define the **file** we will read from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca149be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './data/intro_card.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e1e0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "date     = ft.FeatureSource('Date', ft.FEATURE_TYPE_DATE, format_code='%Y%m%d')\n",
    "card     = ft.FeatureSource('Card', ft.FEATURE_TYPE_STRING)\n",
    "merchant = ft.FeatureSource('Merchant', ft.FEATURE_TYPE_STRING)\n",
    "amount   = ft.FeatureSource('Amount', ft.FEATURE_TYPE_FLOAT_32)\n",
    "mcc      = ft.FeatureSource('MCC', ft.FEATURE_TYPE_CATEGORICAL, default='0000')\n",
    "country  = ft.FeatureSource('Country', ft.FEATURE_TYPE_CATEGORICAL)\n",
    "fraud    = ft.FeatureSource('Fraud', ft.FEATURE_TYPE_INT_8)\n",
    "\n",
    "mcc_oh = ft.FeatureOneHot('MCC_OH', ft.FEATURE_TYPE_INT_8,  mcc)\n",
    "country_oh = ft.FeatureOneHot('Country_OH', ft.FEATURE_TYPE_INT_8, country)\n",
    "fraud_label = ft.FeatureLabelBinary('Fraud_Label', ft.FEATURE_TYPE_INT_8, fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c8c993",
   "metadata": {},
   "source": [
    "### Not being smart about it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2c56e",
   "metadata": {},
   "source": [
    "When we define feature, we provide a `FeatureType`. The FeatureType defines what the dtype of the Pandas DataFrame and Numpy array will be.\n",
    "\n",
    "The `EnginePandas` has a method to build a **Numpy** array instead of a **DataFrame**, it is named `np_from_csv`. We can try to use this to build all created features, like before, and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a46b35df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:59:33.253 eng1n3.common.engine           INFO     Start Engine...\n",
      "2023-04-18 20:59:33.254 eng1n3.pandas.pandasengine     INFO     Pandas Version : 1.5.3\n",
      "2023-04-18 20:59:33.255 eng1n3.pandas.pandasengine     INFO     Numpy Version : 1.23.5\n"
     ]
    },
    {
     "ename": "EnginePandasException",
     "evalue": "Error creating source: Found more than one feature root type. ['STRING', 'FLOAT', 'INTEGER'] in TensorDefinition Features. This process can only handle features of the same root type, for instance only INTEGER or only FLOAT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEnginePandasException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m td \u001b[38;5;241m=\u001b[39m ft\u001b[38;5;241m.\u001b[39mTensorDefinition(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, [date, card, merchant, amount, mcc_oh, country_oh])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m en\u001b[38;5;241m.\u001b[39mEnginePandas(num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m----> 4\u001b[0m     ti \u001b[38;5;241m=\u001b[39m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnp_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Jupyter/lib/python3.10/site-packages/eng1n3/pandas/pandasengine.py:67\u001b[0m, in \u001b[0;36mEnginePandas.np_from_csv\u001b[0;34m(self, target_tensor_def, file, delimiter, quote, time_feature, inference)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnp_from_csv\u001b[39m(\u001b[38;5;28mself\u001b[39m, target_tensor_def: Union[TensorDefinition, Tuple[TensorDefinition, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]],\n\u001b[1;32m     48\u001b[0m                 file: \u001b[38;5;28mstr\u001b[39m, delimiter: \u001b[38;5;28mchr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, quote: \u001b[38;5;28mchr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_feature: Optional[Feature] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m                 inference: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorInstanceNumpy:\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Create a Numpy Array based on a TensorDefinition by reading a file.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m         TensorInstanceNumpy with the Numpy arrays as defined in the target_tensor_def\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[43mEnginePandasValidation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_same_feature_root_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_tensor_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     EnginePandasValidation\u001b[38;5;241m.\u001b[39mval_all_same_learning_category(target_tensor_def)\n\u001b[1;32m     69\u001b[0m     EnginePandasValidation\u001b[38;5;241m.\u001b[39mval_no_none_learning_category(target_tensor_def)\n",
      "File \u001b[0;32m~/Jupyter/lib/python3.10/site-packages/eng1n3/pandas/helpers/validation.py:215\u001b[0m, in \u001b[0;36mEnginePandasValidation.val_same_feature_root_type\u001b[0;34m(target_tensor_def)\u001b[0m\n\u001b[1;32m    213\u001b[0m rt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m([f\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mroot_type \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m td\u001b[38;5;241m.\u001b[39mfeatures]))\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rt) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EnginePandasException(\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound more than one feature root type. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[r\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mr\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mrt]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in TensorDefinition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtd\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis process can only handle features of the same root type, for instance only INTEGER or \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly FLOAT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    219\u001b[0m     )\n",
      "\u001b[0;31mEnginePandasException\u001b[0m: Error creating source: Found more than one feature root type. ['STRING', 'FLOAT', 'INTEGER'] in TensorDefinition Features. This process can only handle features of the same root type, for instance only INTEGER or only FLOAT"
     ]
    }
   ],
   "source": [
    "td = ft.TensorDefinition('Features', [date, card, merchant, amount, mcc_oh, country_oh])\n",
    "\n",
    "with en.EnginePandas(num_threads=1) as e:\n",
    "    ti = e.np_from_csv(td, file, inference=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30106a35",
   "metadata": {},
   "source": [
    "### A bit smarter\n",
    "\n",
    "We get an error, this is expected. The engine is telling us that is can not build *TensorDefinition* because the features are not all of the same **FeatureRootType**.\n",
    "\n",
    "When we want to build a Numpy array we will need to split the features up into several TensorDefinitions, where each *TensorDefinition* only contains feature of a **single FeatureRootType**.\n",
    "\n",
    "For instance we can bundle the mcc_oh and country_oh, they are the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7340348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:59:35.788 eng1n3.common.engine           INFO     Start Engine...\n",
      "2023-04-18 20:59:35.788 eng1n3.pandas.pandasengine     INFO     Pandas Version : 1.5.3\n",
      "2023-04-18 20:59:35.788 eng1n3.pandas.pandasengine     INFO     Numpy Version : 1.23.5\n",
      "2023-04-18 20:59:35.789 eng1n3.pandas.pandasengine     INFO     Building Panda for : All_r_1 from file ./data/intro_card.csv\n",
      "2023-04-18 20:59:35.804 eng1n3.pandas.pandasengine     INFO     Reshaping DataFrame to: All_r_1\n",
      "2023-04-18 20:59:35.804 eng1n3.pandas.pandasengine     INFO     Converting All_r_1 to 1 numpy arrays\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(eng1n3.common.tensorinstance.TensorInstanceNumpy, 1, numpy.ndarray)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = ft.TensorDefinition('Features', [mcc_oh, country_oh])\n",
    "\n",
    "with en.EnginePandas(num_threads=1) as e:\n",
    "    ti = e.np_from_csv(td, file, inference=False)\n",
    "    \n",
    "type(ti), ti.number_of_lists, type(ti.numpy_lists[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad88b66c",
   "metadata": {},
   "source": [
    "This looks better, we have no error and we are getting back an object of `TensorInstanceNumpy`, this is an object that can contain several Numpy arrays. In our case as we had one TensorDefinition as input, we get a TensorInstanceNumpy with exactly one list.\n",
    "\n",
    "We can have a look at the content of that list. It is a matrix (Rank-2 tensor) of size 6 x 7, i.e. 6 rows and 7 columns. The dype is uint8 (a very small integer), and contains zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b36205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 7),\n",
       " array([[1, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 1, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.numpy_lists[0].shape, ti.numpy_lists[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b8598",
   "metadata": {},
   "source": [
    "The content looks a bit cryptic, but we can make it a bit more familiar by building out a `DataFrame` with the same features. And observe that is basically the same data as before, but less visually attractive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66db9a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:59:38.868 eng1n3.common.engine           INFO     Start Engine...\n",
      "2023-04-18 20:59:38.869 eng1n3.pandas.pandasengine     INFO     Pandas Version : 1.5.3\n",
      "2023-04-18 20:59:38.869 eng1n3.pandas.pandasengine     INFO     Numpy Version : 1.23.5\n",
      "2023-04-18 20:59:38.870 eng1n3.pandas.pandasengine     INFO     Building Panda for : Features from file ./data/intro_card.csv\n",
      "2023-04-18 20:59:38.877 eng1n3.pandas.pandasengine     INFO     Reshaping DataFrame to: Features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC__0001</th>\n",
       "      <th>MCC__0002</th>\n",
       "      <th>MCC__0003</th>\n",
       "      <th>MCC__0000</th>\n",
       "      <th>Country__DE</th>\n",
       "      <th>Country__FR</th>\n",
       "      <th>Country__GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MCC__0001  MCC__0002  MCC__0003  MCC__0000  Country__DE  Country__FR  \\\n",
       "0          1          0          0          0            1            0   \n",
       "1          0          1          0          0            0            0   \n",
       "2          0          0          1          0            1            0   \n",
       "3          0          0          1          0            0            1   \n",
       "4          0          1          0          0            0            0   \n",
       "5          0          0          0          1            1            0   \n",
       "\n",
       "   Country__GB  \n",
       "0            0  \n",
       "1            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            1  \n",
       "5            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with en.EnginePandas(num_threads=1) as e:\n",
    "    df = e.df_from_csv(td, file, inference=False)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d93a02",
   "metadata": {},
   "source": [
    "### Multiple TensorDefinitions\n",
    "\n",
    "In a real life case we may not want to be restricted to a single data type and provide more than just the OneHot Features to a model. Luckily we can provide multiple TensorDefinitions to the `np_from_csv` call. Let's define a second `TensorDefinition` for the amount and a third `TensorDefinition` for the Fraud label and ask to build them all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa50feaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 20:59:41.427 eng1n3.common.engine           INFO     Start Engine...\n",
      "2023-04-18 20:59:41.427 eng1n3.pandas.pandasengine     INFO     Pandas Version : 1.5.3\n",
      "2023-04-18 20:59:41.427 eng1n3.pandas.pandasengine     INFO     Numpy Version : 1.23.5\n",
      "2023-04-18 20:59:41.428 eng1n3.pandas.pandasengine     INFO     Building Panda for : All_r_1 from file ./data/intro_card.csv\n",
      "2023-04-18 20:59:41.434 eng1n3.pandas.pandasengine     INFO     Reshaping DataFrame to: All_r_1\n",
      "2023-04-18 20:59:41.435 eng1n3.pandas.pandasengine     INFO     Converting All_r_1 to 3 numpy arrays\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(eng1n3.common.tensorinstance.TensorInstanceNumpy, 3, numpy.ndarray)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_oh     = ft.TensorDefinition('Features_OH', [mcc_oh, country_oh])\n",
    "td_amount = ft.TensorDefinition('Feature_Amount', [amount])\n",
    "td_label  = ft.TensorDefinition('Feature_Fraud', [fraud_label])\n",
    "\n",
    "with en.EnginePandas(num_threads=1) as e:\n",
    "    ti = e.np_from_csv(\n",
    "        (td_oh, td_amount, td_label),  # A Tuple of multiple TensorDefinitions\n",
    "        file, \n",
    "        inference=False)\n",
    "    \n",
    "type(ti), ti.number_of_lists, type(ti.numpy_lists[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43ea6e",
   "metadata": {},
   "source": [
    "As we asked for 3 TensorDefinitions to be built, we get 3 Numpy arrays back in the TensorInstanceNumpy. The first list is the one we recognize from the previous examples, the OneHot encoded 'Mercant' and 'Country' fields.\n",
    "\n",
    "The second list is a 6x1 matrix containing the amounts of each sample. We have 6 samples and 1 feature. \n",
    "\n",
    "And the third list is the 'Fraud', column, that it what we will use as **label** when we run predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8befd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 7),\n",
       " array([[1, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 1, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.numpy_lists[0].shape, ti.numpy_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36fad2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 1),\n",
       " array([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.numpy_lists[1].shape, ti.numpy_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c11c480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 1),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]], dtype=int8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.numpy_lists[2].shape, ti.numpy_lists[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728a160",
   "metadata": {},
   "source": [
    "### Label Data\n",
    "\n",
    "The attentive reader will note that the third list containing the label has the same dtype (int8) as the first list and wonder why we did not build them together.\n",
    "\n",
    "Neural Nets generally need a target, the objective they are going to solve for. This is often referred to as **label**, it is generally fed as separate tensor to the model. That is why we have it a distinctive TensorDefinition and build it out seperately. It is also usefull for production modes, typically you will not provide the label in production, so it's best to keep it seperated from the actual input data.\n",
    "\n",
    "If and when we want to train a Neural Net Model, we'll have to tell it where it can find the label. The TensorInstanceNumpy understands that a TensorDefinition that only contains `FeatureLabel` classes is very likely to be the label we will want to use.\n",
    "\n",
    "We can ask it which Numpy arrray(s) it thinks are the label(s), and index into the TensorInstance. That will come in handly later down the line to correctly use the label in the Neural Net Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e72a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.label_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f19035a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.numpy_lists[ti.label_indexes[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3135b",
   "metadata": {},
   "source": [
    "### Split data\n",
    "When you train a Neural Net, you'll always want to split your data into a training, validation and test set.\n",
    "- The training set is the one used to train the model.\n",
    "- The validation set is used to make sure the model does not overfit during training\n",
    "- The test set is used totally at the end of the modelling process to publish results, it should really only be used once.\n",
    "\n",
    "Now that we have a `TensorInstance` object we can ask it to perform a sequential split. This normally the best way to split data that has a time dimension. **Never random shuffle transactional data**, that can create data leakage. \n",
    "\n",
    "Make sure the data is **ordered** in the time dimension before applying the split, the split function itself does not order, it assumes the data *is* ordered.\n",
    "\n",
    "Below call to `split_sequential` asks to split the file sequentially, the last '1' record will be *test*, the previous 2 will be *validation* and everything before that will be *training*.\n",
    "\n",
    "Note how the result we get has each of the Numpy arrays split in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72112bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = ti.split_sequential(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdb895d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorInstance with shapes: ((3, 7), (3, 1), (3, 1)),\n",
       " TensorInstance with shapes: ((2, 7), (2, 1), (2, 1)),\n",
       " TensorInstance with shapes: ((1, 7), (1, 1), (1, 1)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1973ca8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 1, 0, 0]], dtype=uint8),\n",
       " array([[1.],\n",
       "        [2.],\n",
       "        [3.]], dtype=float32),\n",
       " array([[0],\n",
       "        [0],\n",
       "        [1]], dtype=int8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.numpy_lists[0], train.numpy_lists[1], train.numpy_lists[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7002c78",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "At this point we have created something that can almost readily be used in a training, validation and testing methodoly for a Neural Net. Next up is creating and training models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
